{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LING 83800 Homework 2\n",
    "\n",
    "In this homework, we will be using finite state machines to restore vowels to vowelless text using pynini. While this is not very useful for English, but it is for languages like Hebrew and Arabic where vowels are regularly omitted.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "1. Clone this repository to your local machine\n",
    "1. Make sure pynini is installed (`conda install -c conda-forge pynini`)\n",
    "1. Complete the cells with instructions\n",
    "1. Submit your final notebook via blackboard.\n",
    "\n",
    "## Tips\n",
    "\n",
    "You will find the [pynini documentation](http://www.openfst.org/twiki/bin/view/GRM/PyniniDocs) useful in completing this assignment.\n",
    "\n",
    "Particularly useful pynini functions for this assignment are:\n",
    "   * `pynini.cdrewrite()`\n",
    "   * `pynini.concat()`\n",
    "   * `pynini.compose()`\n",
    "   * `pynini.invert()`\n",
    "   * `pynini.shortestpath()`\n",
    "   * `pynini.union()`\n",
    "   * `pynini.Fst.closure()`\n",
    "   * `pynini.Fst.num_states()`\n",
    "   * `pynini.Fst.optimize()`\n",
    "   * `pynini.Fst.project()`\n",
    "   * `pynini.Fst.string()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pynini\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Finite state acceptor\n",
    "\n",
    "In this first problem, we will make a finite state acceptor for all valid English words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Toy vocabulary\n",
    "\n",
    "Here is an FSA that accepts the three words \"at\", \"an\", and \"age\" that we will use as an example. Note the use of the `*` operator on the list to expand it into the list of arguments to `pynini.union()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: FST Pages: 1 -->\n",
       "<svg width=\"409pt\" height=\"168pt\"\n",
       " viewBox=\"0.00 0.00 409.00 168.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 164)\">\n",
       "<title>FST</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-164 405,-164 405,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" stroke-width=\"2\" cx=\"18\" cy=\"-80\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"18\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"98\" cy=\"-136\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"98\" y=\"-132.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M33.0474,-90.5332C44.7801,-98.7461 61.2816,-110.2971 74.7158,-119.7011\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"72.8206,-122.6467 83.0201,-125.5141 76.8349,-116.9121 72.8206,-122.6467\"/>\n",
       "<text text-anchor=\"middle\" x=\"58\" y=\"-114.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">97</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>3</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"98\" cy=\"-80\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"98\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">3</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;3 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M36.1532,-80C46.0749,-80 58.5833,-80 69.7508,-80\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"69.9186,-83.5001 79.9186,-80 69.9186,-76.5001 69.9186,-83.5001\"/>\n",
       "<text text-anchor=\"middle\" x=\"58\" y=\"-83.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>6</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"98\" cy=\"-26\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"98\" y=\"-22.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">6</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;6 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>0&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M33.0474,-69.843C44.7801,-61.9234 61.2816,-50.7849 74.7158,-41.7168\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"76.6898,-44.6072 83.0201,-36.1114 72.7734,-38.8052 76.6898,-44.6072\"/>\n",
       "<text text-anchor=\"middle\" x=\"58\" y=\"-59.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"189\" cy=\"-138\" rx=\"18\" ry=\"18\"/>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"189\" cy=\"-138\" rx=\"22\" ry=\"22\"/>\n",
       "<text text-anchor=\"middle\" x=\"189\" y=\"-134.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">2</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M116.4152,-136.4047C127.8895,-136.6569 142.9769,-136.9885 156.4226,-137.284\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"156.6789,-140.7904 166.7535,-137.5111 156.8328,-133.7921 156.6789,-140.7904\"/>\n",
       "<text text-anchor=\"middle\" x=\"141.5\" y=\"-140.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">116</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>4</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"189\" cy=\"-80\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"189\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">4</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M116.4152,-80C129.0791,-80 146.1442,-80 160.5459,-80\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"160.9228,-83.5001 170.9227,-80 160.9227,-76.5001 160.9228,-83.5001\"/>\n",
       "<text text-anchor=\"middle\" x=\"141.5\" y=\"-83.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">97</text>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"189\" cy=\"-25\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"189\" y=\"-21.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">7</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>6&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M116.4152,-25.7976C129.0791,-25.6585 146.1442,-25.4709 160.5459,-25.3127\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"160.9618,-28.8084 170.9227,-25.1987 160.8848,-21.8088 160.9618,-28.8084\"/>\n",
       "<text text-anchor=\"middle\" x=\"141.5\" y=\"-28.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">97</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>5</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"284\" cy=\"-80\" rx=\"18\" ry=\"18\"/>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"284\" cy=\"-80\" rx=\"22\" ry=\"22\"/>\n",
       "<text text-anchor=\"middle\" x=\"284\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">5</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M207.317,-80C219.8124,-80 236.7069,-80 251.458,-80\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"251.7268,-83.5001 261.7267,-80 251.7267,-76.5001 251.7268,-83.5001\"/>\n",
       "<text text-anchor=\"middle\" x=\"236.5\" y=\"-83.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">110</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"284\" cy=\"-22\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"284\" y=\"-18.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">8</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>7&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M207.317,-24.4216C220.9851,-23.9899 239.9167,-23.3921 255.5492,-22.8984\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"255.8548,-26.3906 265.7393,-22.5767 255.6338,-19.3941 255.8548,-26.3906\"/>\n",
       "<text text-anchor=\"middle\" x=\"236.5\" y=\"-26.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">103</text>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"379\" cy=\"-22\" rx=\"18\" ry=\"18\"/>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"379\" cy=\"-22\" rx=\"22\" ry=\"22\"/>\n",
       "<text text-anchor=\"middle\" x=\"379\" y=\"-18.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">9</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>8&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M302.317,-22C314.8124,-22 331.7069,-22 346.458,-22\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"346.7268,-25.5001 356.7267,-22 346.7267,-18.5001 346.7268,-25.5001\"/>\n",
       "<text text-anchor=\"middle\" x=\"331.5\" y=\"-25.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">101</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<vector Fst at 0x7f08dc01daf0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = [\"at\", \"an\", \"age\"]\n",
    "at_an_age_only = pynini.union(*vocab)\n",
    "at_an_age_only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that it accepts any of those words, but nothing else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'at'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pynini.compose(\"at\", at_an_age_only).string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at\n",
      "an\n",
      "age\n",
      "Failed: and\n",
      "Failed: aardvark\n"
     ]
    }
   ],
   "source": [
    "for word in ['at', 'an', 'age', 'and', 'aardvark']:\n",
    "    try:\n",
    "        print(pynini.compose(word, at_an_age_only).string())\n",
    "    except pynini.FstOpError:\n",
    "        print(\"Failed:\", word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Use concatenation and closure to create an FSA that accepts sequences of the words \"at\", \"an\", and \"age\" (in any order) separated by spaces\n",
    "\n",
    "For example, it should accept \"at an age\", but it should reject \"at and age\" and \"atanage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your code here, assigning the FSA to at_an_age\n",
    "\n",
    "at_an_age = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FstArgError",
     "evalue": "Cannot encode as string: None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFstArgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8ca342c1e353>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mpynini\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"at an age\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mat_an_age\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"at an age\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Correctly accepted\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"at an age\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbad_sentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'at and age'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'atanage'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msrc/pynini.pyx\u001b[0m in \u001b[0;36mpynini._compose_patch.patch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/pynini.pyx\u001b[0m in \u001b[0;36mpynini._compile_or_copy_two_Fsts\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/pynini.pyx\u001b[0m in \u001b[0;36mpynini.acceptor\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/pywrapfst.pyx\u001b[0m in \u001b[0;36mpywrapfst.tostring\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFstArgError\u001b[0m: Cannot encode as string: None"
     ]
    }
   ],
   "source": [
    "assert pynini.compose(\"at an age\", at_an_age).string() == \"at an age\"\n",
    "print(\"Correctly accepted\", \"at an age\")\n",
    "\n",
    "for bad_sentence in ['at and age', 'atanage']:\n",
    "    try:\n",
    "        print(pynini.compose(bad_sentence, at_an_age_only).string())\n",
    "    except pynini.FstOpError:\n",
    "        print(\"Correctly rejected\", bad_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Write a function to convert an FSA that accepts individual words into an FSA that accepts space-separated sequences of those words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your code here, call the function space_separated_closure\n",
    "\n",
    "def space_separated_closure(fst):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test that it gives you the same FSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'optimize'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0d1309ab2bdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mat_an_age\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mspace_separated_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mat_an_age_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'optimize'"
     ]
    }
   ],
   "source": [
    "assert pynini.equivalent(at_an_age.optimize(), space_separated_closure(at_an_age_only).optimize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Create an FSA that accepts individual English words\n",
    "\n",
    "I have given you a file containing \"all\" of the valid English words that we are considering here called \"english_all.txt\". Each line contains one word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your code here, put the FSA in the variable english\n",
    "\n",
    "english = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test that it works on valid words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FstArgError",
     "evalue": "Cannot encode as string: None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFstArgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-69c5e6f39896>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"pacheco\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"extravagant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hevey\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"anchorage\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wearers\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"corroded\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hallen\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hegenna\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"nostrand\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"silvershoe\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpynini\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menglish\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Succeeded for\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msrc/pynini.pyx\u001b[0m in \u001b[0;36mpynini._compose_patch.patch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/pynini.pyx\u001b[0m in \u001b[0;36mpynini._compile_or_copy_two_Fsts\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/pynini.pyx\u001b[0m in \u001b[0;36mpynini.acceptor\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/pywrapfst.pyx\u001b[0m in \u001b[0;36mpywrapfst.tostring\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFstArgError\u001b[0m: Cannot encode as string: None"
     ]
    }
   ],
   "source": [
    "for word in [\"pacheco\", \"extravagant\", \"hevey\", \"anchorage\", \"wearers\", \"corroded\", \"hallen\", \"hegenna\", \"nostrand\", \"silvershoe\"]:\n",
    "    pynini.compose(word, english).string()\n",
    "    print(\"Succeeded for\", word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test that it doesn't work on invalid words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FstArgError",
     "evalue": "Cannot encode as string: None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFstArgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c99b7676d22a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbad_word\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"sooper\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"seekrit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"deeeecoder\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ringgg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"more than one word\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpynini\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbad_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menglish\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mpynini\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFstOpError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Correctly rejected\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbad_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msrc/pynini.pyx\u001b[0m in \u001b[0;36mpynini._compose_patch.patch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/pynini.pyx\u001b[0m in \u001b[0;36mpynini._compile_or_copy_two_Fsts\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/pynini.pyx\u001b[0m in \u001b[0;36mpynini.acceptor\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/pywrapfst.pyx\u001b[0m in \u001b[0;36mpywrapfst.tostring\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFstArgError\u001b[0m: Cannot encode as string: None"
     ]
    }
   ],
   "source": [
    "for bad_word in [\"sooper\", \"seekrit\", \"deeeecoder\", \"ringgg\", \"more than one word\"]:\n",
    "    try:\n",
    "        print(pynini.compose(bad_word, english).string())\n",
    "    except pynini.FstOpError:\n",
    "        print(\"Correctly rejected\", bad_word)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Create the space-separated closure of english words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your code here. Call the FSA english_sentences\n",
    "\n",
    "english_sentences = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test that it works on valid sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FstArgError",
     "evalue": "Cannot encode as string: None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFstArgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-73df645a2e1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"more than one word\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pacheco extravagant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hevey anchorage wearers\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"corroded hallen hegenna nostrand\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"silvershoe\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpynini\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menglish_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Succeeded for\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msrc/pynini.pyx\u001b[0m in \u001b[0;36mpynini._compose_patch.patch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/pynini.pyx\u001b[0m in \u001b[0;36mpynini._compile_or_copy_two_Fsts\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/pynini.pyx\u001b[0m in \u001b[0;36mpynini.acceptor\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/pywrapfst.pyx\u001b[0m in \u001b[0;36mpywrapfst.tostring\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFstArgError\u001b[0m: Cannot encode as string: None"
     ]
    }
   ],
   "source": [
    "for sentence in [\"more than one word\", \"pacheco extravagant\", \"hevey anchorage wearers\", \"corroded hallen hegenna nostrand\", \"silvershoe\"]:\n",
    "    pynini.compose(sentence, english_sentences).string()\n",
    "    print(\"Succeeded for\", sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test that it doesn't work on invalid sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FstArgError",
     "evalue": "Cannot encode as string: None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFstArgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-2e4b47af4352>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbad_sentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"sooper seekrit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"deeeecoder\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ringgg more than one word\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpynini\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbad_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menglish_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mpynini\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFstOpError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Correctly rejected\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbad_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msrc/pynini.pyx\u001b[0m in \u001b[0;36mpynini._compose_patch.patch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/pynini.pyx\u001b[0m in \u001b[0;36mpynini._compile_or_copy_two_Fsts\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/pynini.pyx\u001b[0m in \u001b[0;36mpynini.acceptor\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/pywrapfst.pyx\u001b[0m in \u001b[0;36mpywrapfst.tostring\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFstArgError\u001b[0m: Cannot encode as string: None"
     ]
    }
   ],
   "source": [
    "for bad_sentence in [\"sooper seekrit\", \"deeeecoder\", \"ringgg more than one word\"]:\n",
    "    try:\n",
    "        print(pynini.compose(bad_sentence, english_sentences).string())\n",
    "    except pynini.FstOpError:\n",
    "        print(\"Correctly rejected\", bad_sentence)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. A transducer to remove vowels\n",
    "\n",
    "In this section, we will create an FST to remove vowels from strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = list(string.ascii_lowercase) + [\" \", \"-\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Make the transducer to remove vowels\n",
    "\n",
    "You will need to make a `pynini.transducer()` from vowels to the empty string and then use `pynini.cdrewrite()` to make a context-dependent rewrite transducer, but don't give it any context (use the empty string for the left and right context). You will also need to define `sigma_star` the closure of the `alphabet` just defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your code here. Put the vowel remover transformer in the variable_vowel_remover\n",
    "\n",
    "vowel_remover = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FstArgError",
     "evalue": "Cannot encode as string: None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFstArgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-86a3b03310ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mpynini\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dendrochronology uncharacteristic shortsightedness\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvowel_remover\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'dndrchrnlgy nchrctrstc shrtsghtdnss'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Worked'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msrc/pynini.pyx\u001b[0m in \u001b[0;36mpynini._compose_patch.patch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/pynini.pyx\u001b[0m in \u001b[0;36mpynini._compile_or_copy_two_Fsts\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/pynini.pyx\u001b[0m in \u001b[0;36mpynini.acceptor\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/pywrapfst.pyx\u001b[0m in \u001b[0;36mpywrapfst.tostring\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFstArgError\u001b[0m: Cannot encode as string: None"
     ]
    }
   ],
   "source": [
    "assert pynini.compose(\"dendrochronology uncharacteristic shortsightedness\", vowel_remover).string() == 'dndrchrnlgy nchrctrstc shrtsghtdnss'\n",
    "print('Worked')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a function to do that for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_vowels(sentence, vowel_remover):\n",
    "    return pynini.compose(sentence, vowel_remover).string()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Make an FST to add vowels back to strings\n",
    "\n",
    "Use the function `pynini.invert()` to exchange the input and output strings of the FST relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your code here, call your vowel-adding FST vowel_adder\n",
    "\n",
    "vowel_adder = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Write a function to apply the vowel_adder to a string\n",
    "\n",
    "1. Compose the string with the vowel_adder\n",
    "1. Project the results onto the output symbols\n",
    "1. Find the shortest path through this combined FSA\n",
    "1. Convert to a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your code here. Call your decoding function add_vowels()\n",
    "\n",
    "def add_vowels(sentence, vowel_adder):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_vowels('dndrchrnlgy nchrctrstc shrtsghtdnss', vowel_adder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Discuss why it doesn't work\n",
    "\n",
    "Write in the markdown box below:\n",
    "1. What is going on\n",
    "1. Why it is going on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TODO: Your markdown goes here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Use your english sentence FSA to require your vowel adder to emit valid english sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Compose your vowel adder FST with your english sentence FSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your code here. Call the resulting FST vowel_adder_valid\n",
    "\n",
    "vowel_adder_valid = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-a5792a5eb9c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0madd_vowels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dndrchrnlgy nchrctrstc shrtsghtdnss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvowel_adder_valid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'dendrochronology uncharacteristic shortsightedness'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Success!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert add_vowels('dndrchrnlgy nchrctrstc shrtsghtdnss', vowel_adder_valid) == 'dendrochronology uncharacteristic shortsightedness'\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "FstArgError",
     "evalue": "Cannot encode as string: None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFstArgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-a7d746e3a9d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"roark foot rerun leading overly cross birds\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreconstruction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_vowels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremove_vowels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvowel_remover\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvowel_adder_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreconstruction\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Not reconstructed:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"->\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstruction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-021b69c42700>\u001b[0m in \u001b[0;36mremove_vowels\u001b[0;34m(sentence, vowel_remover)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mremove_vowels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvowel_remover\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpynini\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvowel_remover\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32msrc/pynini.pyx\u001b[0m in \u001b[0;36mpynini._compose_patch.patch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/pynini.pyx\u001b[0m in \u001b[0;36mpynini._compile_or_copy_two_Fsts\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/pynini.pyx\u001b[0m in \u001b[0;36mpynini.acceptor\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/pywrapfst.pyx\u001b[0m in \u001b[0;36mpywrapfst.tostring\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFstArgError\u001b[0m: Cannot encode as string: None"
     ]
    }
   ],
   "source": [
    "sentence = \"roark foot rerun leading overly cross birds\"\n",
    "reconstruction = add_vowels(remove_vowels(sentence, vowel_remover), vowel_adder_valid)\n",
    "if reconstruction != sentence:\n",
    "    print(\"Not reconstructed:\", sentence, \"->\", reconstruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Discuss why it doesn't work\n",
    "\n",
    "Write in the markdown box below:\n",
    "1. What is going on\n",
    "1. Why it is going on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TODO: Your markdown goes here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Try adding a (character) language model\n",
    "\n",
    "I have created a 5-gram character language model in the file `english_all.lm5`. I used the following OpenGRM commands to do so:\n",
    "\n",
    "```bash\n",
    "farcompilestrings --far_type=compact_string --token_type=byte english_all.txt english_all.far\n",
    "ngramcount --order=5 --require_symbols=false english_all.far english_all.cnts5\n",
    "ngrammake --method=witten_bell english_all.cnts5 english_all.lm5\n",
    "```\n",
    "\n",
    "Load the language model using `pynini.Fst.read()` and compose your `vowel_adder_valid` FST with it to make a new FST that weights the translations with this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your code goes here, call your model vowel_adder_lm5\n",
    "\n",
    "vowel_adder_lm5 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "FstArgError",
     "evalue": "Cannot encode as string: None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFstArgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-195df6c00a00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"roark foot rerun leading overly cross birds\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreconstruction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_vowels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremove_vowels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvowel_remover\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvowel_adder_lm5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreconstruction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Success\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-021b69c42700>\u001b[0m in \u001b[0;36mremove_vowels\u001b[0;34m(sentence, vowel_remover)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mremove_vowels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvowel_remover\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpynini\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvowel_remover\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32msrc/pynini.pyx\u001b[0m in \u001b[0;36mpynini._compose_patch.patch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/pynini.pyx\u001b[0m in \u001b[0;36mpynini._compile_or_copy_two_Fsts\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/pynini.pyx\u001b[0m in \u001b[0;36mpynini.acceptor\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/pywrapfst.pyx\u001b[0m in \u001b[0;36mpywrapfst.tostring\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFstArgError\u001b[0m: Cannot encode as string: None"
     ]
    }
   ],
   "source": [
    "sentence = \"roark foot rerun leading overly cross birds\"\n",
    "reconstruction = add_vowels(remove_vowels(sentence, vowel_remover), vowel_adder_lm5)\n",
    "if reconstruction == sentence:\n",
    "    print(\"Success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Optional: Make it better\n",
    "\n",
    "Use the below function to evaluate the word reconstruction accuracy of your model on the sentences in the file `strings.txt`. The `vowel_adder_valid` model gets 26% of the words right. The `vowel_adder_lm5` model gets 35% of the words right. Can you make it better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_words(vowel_adder):\n",
    "    right, total = 0, 1e-9\n",
    "    with open(\"strings.txt\", \"r\") as strings:\n",
    "        for string in strings:\n",
    "            string = string.strip()\n",
    "            words = string.split(\" \")\n",
    "            total += len(words)\n",
    "            try:\n",
    "                no_vowels = remove_vowels(string.strip(), vowel_remover)\n",
    "                re_voweled = add_vowels(no_vowels, vowel_adder)\n",
    "                re_worded = re_voweled.split(\" \")\n",
    "                for pred, gt in zip(re_worded, words):\n",
    "                    if pred == gt:\n",
    "                        right += 1\n",
    "            except pynini.FstOpError:\n",
    "                # print(\"Failed:\", string)\n",
    "                pass\n",
    "    return right / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "FstArgError",
     "evalue": "Cannot encode as string: None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFstArgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-f81bf41ce934>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvowel_adder_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-9fd1174841a2>\u001b[0m in \u001b[0;36mevaluate_words\u001b[0;34m(vowel_adder)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                 \u001b[0mno_vowels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_vowels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvowel_remover\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                 \u001b[0mre_voweled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_vowels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_vowels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvowel_adder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mre_worded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre_voweled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-021b69c42700>\u001b[0m in \u001b[0;36mremove_vowels\u001b[0;34m(sentence, vowel_remover)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mremove_vowels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvowel_remover\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpynini\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvowel_remover\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32msrc/pynini.pyx\u001b[0m in \u001b[0;36mpynini._compose_patch.patch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/pynini.pyx\u001b[0m in \u001b[0;36mpynini._compile_or_copy_two_Fsts\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/pynini.pyx\u001b[0m in \u001b[0;36mpynini.acceptor\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/pywrapfst.pyx\u001b[0m in \u001b[0;36mpywrapfst.tostring\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFstArgError\u001b[0m: Cannot encode as string: None"
     ]
    }
   ],
   "source": [
    "evaluate_words(vowel_adder_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "FstArgError",
     "evalue": "Cannot encode as string: None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFstArgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-46ee3ade0ac8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvowel_adder_lm5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-9fd1174841a2>\u001b[0m in \u001b[0;36mevaluate_words\u001b[0;34m(vowel_adder)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                 \u001b[0mno_vowels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_vowels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvowel_remover\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                 \u001b[0mre_voweled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_vowels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_vowels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvowel_adder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mre_worded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre_voweled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-021b69c42700>\u001b[0m in \u001b[0;36mremove_vowels\u001b[0;34m(sentence, vowel_remover)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mremove_vowels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvowel_remover\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpynini\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvowel_remover\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32msrc/pynini.pyx\u001b[0m in \u001b[0;36mpynini._compose_patch.patch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/pynini.pyx\u001b[0m in \u001b[0;36mpynini._compile_or_copy_two_Fsts\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/pynini.pyx\u001b[0m in \u001b[0;36mpynini.acceptor\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/pywrapfst.pyx\u001b[0m in \u001b[0;36mpywrapfst.tostring\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFstArgError\u001b[0m: Cannot encode as string: None"
     ]
    }
   ],
   "source": [
    "evaluate_words(vowel_adder_lm5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
